<?xml version="1.0" encoding="ISO-8859-15"?>
<!DOCTYPE book
[
<!ENTITY % entities SYSTEM 'catalog.ent'>
<!ENTITY % local.common.attrib "infoid CDATA #IMPLIED">
<!ATTLIST bookinfo code CDATA #REQUIRED>
%entities;
]>



<book id="aims_training%book">
  <bookinfo code='aims_training'><title>Aims tutorial</title></bookinfo>


<chapter><title>Foreward</title>
&disclaimer_en;
<para>In order to work through the following sections, please download the demonstration data from one of the following links:
 <itemizedlist>
 <listitem><ulink url="ftp://ftp.cea.fr/pub/dsv/anatomist/data/demo_data_td_2007.zip">ftp://ftp.cea.fr/pub/dsv/anatomist/data/demo_data_td_2007.zip</ulink></listitem>
 <listitem><ulink url="ftp://ftp.cea.fr/pub/dsv/anatomist/data/demo_data_td_2007.zip">ftp://ftp.cea.fr/pub/dsv/anatomist/data/demo_data_td_2007.tar.gz</ulink></listitem>
 <listitem>Section <emphasis>Exemple data</emphasis> from <ulink url="http://brainvisa.info/downloadpage.html">http://brainvisa.info/downloadpage.html</ulink></listitem>
</itemizedlist>
</para>
<para>For more information concerning the installation, please refer to <ulink url="#bv_man%book"> the handbook of BrainVISA</ulink>.</para>
<para>In order to read the help of one commande line, either tape <emphasis> name_commmande -h</emphasis> or refer to the list of commande lines on <ulink url="$PATH_WEB;" target='blank'>http://brainvisa.info</ulink>.</para>
</chapter>


<!-->             <-->
<chapter>
<title>Basic command lines </title>

<sect1 id='aims_training%aimsfileconvert' infoid='conversion of file'>
<title>AimsFileConvert: Performs file format and data conversion</title>

<para><emphasis role='bold'>HELP:</emphasis> <ulink url='&PATH_WEB;#aims_AimsFileConvert' target='blank'>command help for AimsFileConvert</ulink></para>
<para><emphasis role='bold'>DATA:</emphasis> <filename>&DIR_ANAT;objects/3d/gis/subject01.ima</filename>.</para>
<para><emphasis role='bold'>EXAMPLE:</emphasis> here is the conversion from GIS to ANALYZE format.</para>
<screen>
prompt% AimsFileConvert -i subject01.ima -o subject01.img
</screen>
<para><emphasis role='bold'>NOTE:</emphasis> if you work with dicom files, all slices of the same acquisition must be located in the same directory.</para>
</sect1>


<sect1 id='aims_training%aimssubvolume' infoid='using of AimsSubVolume and application to diffusion data'>
<title>AimsSubVolume: Carve a subvolume in the input volume </title>

<para><emphasis role='bold'>HELP:</emphasis> <ulink url='&PATH_WEB;#aims_AimsSubVolume' target='blank'>command help for AimsSubVolume</ulink></para>

<para><emphasis role='bold'>DATA:</emphasis> <filename>&DIR_DEMO;AimsSubVolume/diff_data.ima</filename>, diffusion volume of size [256, 256, 23, 22].</para>

<para><emphasis role='bold'>EXAMPLE 1: GET T2 VOLUME FROM DIFFUSION DATA.</emphasis> In order to get the first volume of the 4th dimension, which corresponds to a T2 volume, you can use the AimsSubVolume command in this way:  </para>

<screen>
prompt%    
prompt% AimsSubVolume -i diff_data.ima -o t2.ima -t 0 -T 0
Input volume dimensions : 256 256 23 22
Output volume dimensions : 256 256 23 1
prompt%    
</screen>
<para>NOTE: concerning a volume of size [x, y, z, 3] has 3 time step, indices start at 0, so the time index must have a value between 0 and 2. This information can be read in the header file or into an anatomist browser.</para> 
 
<para><emphasis role='bold'>EXAMPLE 2: GET THE FIRST 3 DIFFUSION VOLUMES FROM THE DIFFUSION DATA.</emphasis> In order to get the first 3 volumes of diffusion data only<!--, you can do the following-->:</para>
 <screen>
prompt% AimsSubVolume -i diff_data.ima -o vol1.ima vol2.ima vol3.ima -t 1 2 3 -T 1 2 3
Input volume dimensions : 256 256 23 22
Output volume dimensions : 256 256 23 1
Input volume dimensions : 256 256 23 22
Output volume dimensions : 256 256 23 1
Input volume dimensions : 256 256 23 22
Output volume dimensions : 256 256 23 1
prompt%
</screen>
  
<para><emphasis role='bold'>EXAMPLE 3: GET ALL DIFFUSION VOLUMES FROM DIFFUSION DATA.</emphasis> In order to remove the T2 data from diffusion data and to keep only the diffusion data<!--, you can do the following-->: </para>
<screen>
prompt%% AimsSubVolume -i diff_data.ima -o diff.ima -t 1 -T 21
Input volume dimensions : 256 256 23 22
Output volume dimensions : 256 256 23 21
prompt%
</screen>  

</sect1>
  
  
<sect1 id='aims_training%aimsthreshold' infoid='using of AimsThreshold and application to diffusion data'><title>AimsThreshold: Threshold on data</title>

<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsThreshold' target='blank'>command help for AimsThreshold</ulink></para>

<para><emphasis role='bold'>DATA:</emphasis> <filename>&DIR_DEMO;AimsThreshold/voronoi_subject01.ima</filename>.</para>

<para><emphasis role='bold'>EXAMPLE: select a label.</emphasis> For instance, your image is a label volume with 4 values: label 0 = background, label 1 = one hemisphere, label 2 = second hemisphere and label 3 = cerebellum. If you want to remove the cerebellum, you can set up a threshold to keep all values lower than 3:</para>
<screen>
prompt% AimsThreshold -i voronoi_lesson1.ima -o hemi_only.ima -m lt -t 3
</screen>

<figure><title>Select label</title>
<mediaobject>
	<imageobject role="fop"><imagedata fileref="&DIR_IMG;aimsthreshold.png" format="PNG"  width="150"/></imageobject>
	<imageobject role="html"><imagedata fileref="&DIR_IMG;aimsthreshold.png" format="PNG"/></imageobject>
</mediaobject>
</figure>


</sect1> 



<sect1 id='aims_training%aimsgraphmesh' infoid='using of AimsGraphMesh'>
<title>AimsGraphMesh: Performs graph storage conversion and sub-buckets meshing. This command is an improved version of AimsGraphConvert</title>

<para><emphasis role='bold'>HELP:</emphasis> <ulink url='&PATH_WEB;#aims_AimsGraphMesh' target='blank'>command help for AimsGraphMesh</ulink></para>

<para><emphasis role='bold'>DATA:</emphasis> <filename>&DIR_ANAT;objects/roi/basal_ganglia.arg</filename> and <filename>&DIR_ANAT;objects/roi/basal_ganglia.dim</filename>.</para>
	
<para><emphasis role='bold'>EXAMPLE: mesh a ROI graph.</emphasis> The viewing will be enhanced if the ROI graph is meshed.</para>
<screen>
prompt%  AimsGraphMesh -i basal_ganglia.arg -o mesh_basal_ganglia.arg
Warning: wrong filename_base in graph, trying to fix it
filename_base : mesh_basal_ganglia.data
bound : (121 ,127 ,66)
reading slice      :  67
getting interface  : done
processing mesh    : done
clearing interface : done
bound : (151 ,153 ,66)
reading slice      :  67
getting interface  : done
processing mesh    : done
clearing interface : done
bound : (153 ,137 ,71)
reading slice      :  72
getting interface  : done
processing mesh    : done
clearing interface : done
....
saving all
</screen>

<figure><title>Viewing of non-meshed and meshed ROI</title>
<mediaobject>
	<imageobject role="fop"><imagedata fileref="&DIR_IMG;aimsgraphmesh.png" format="PNG"  width="150"/></imageobject>
	<imageobject role="html"><imagedata fileref="&DIR_IMG;aimsgraphmesh.png" format="PNG"/></imageobject>
</mediaobject>
</figure>


</sect1> 



<sect1 id='aims_training%aimsroifeatures' infoid='using of AimsRoiFeatures'>
<title>AimsRoiFeatures: Compute scalar features (mean, volume ...) from regions of interest.</title>

<para><emphasis role='bold'>HELP:</emphasis> <ulink url='&PATH_WEB;#aims_AimsRoiFeatures' target='blank'>command help for AimsRoiFeatures</ulink></para>
	
<para><emphasis role='bold'>DATA:</emphasis> <filename>&DIR_ANAT;objects/roi/anat_demo_roi.ima</filename> and <filename>&DATA_DEMO;AimsRoiFeatures/masque_thalamus_gauche.ima</filename></para>

<para>Here is an example using a binary mask (so all voxels are set to <emphasis>1</emphasis>, in other words there is a label called <emphasis>1</emphasis>) and a volume: </para>
<screen>
prompt% AimsRoiFeatures -i masque_thalamus_gauche.ima --imageStatistics 1:anat_demo_roi.ima -o roi_features.txt
prompt% more features.txt
attributes = {
'format': 'features_1.0',
'content_type': 'roi_features',
'1': {
'point_count': 6502,
'volume': 6857.58,
'1': {
'mean': 48.797,
'stddev': 8.32696,
'min': 21.0003,
'max': 69.9999,
'median': 50,
},
},
}
</screen>

</sect1> 







<!-- 
<sect1 id='aims_training%aimsmasscenter' infoid=''>
<title>AimsMassCenter: Computes position of the mass center of the image</title>
  
<sect2><title>Options</title>  
<para>
<screen>
Computes position of the mass center of the image

Options 

-i | input &lt;file name (read only): { Volume of FLOAT, Volume of S16, Volume
    of S8, Volume of U8 }&gt;  input data

[ -b |  binary &lt;boolean&gt; ]
    consider input image as binary data

[  verbose [ &lt;S32&gt; ] ]
    Set verbosity level (default = 0, without value = 1)

[ -h |  help &lt;boolean&gt; ]
    show help message

[  version &lt;boolean&gt; ]
    show Cartograph version

[  info &lt;boolean&gt; ]
    show libraries information (install, plugins, paths, etc.)

[  optionsfile &lt;string&gt; ]
    Read additional commandline options from the specified file (one switch or
    value per line)

</screen>
</para>
</sect2>
  
<sect2><title>Example: </title>  
  <para> </para>
  <screen>
prompt%    
prompt%
prompt%
</screen>
<para><emphasis rol="bold">What means mass and vol ?</emphasis></para>
<para>Your volume is composed by voxels, which have a grey level, a label or a value (0/1 for binary volume) and size in x, y and z.
Then several things can be computed:</para> 
<para>Voxel_volume = sizeX * sizeY * sizeZ in cm3</para>
<para>Mass = Voxel_volume * sum of voxel value</para>
<para>Volume = Voxel_volume * number of voxels </para>
<para></para>
<para>This command is used for PET data, this data are composed with a temporal dimension. Thus in this command, if your data are n 
frame then you will have n lines plus a "General" line otherwise you will obtain "0" line and the same with "General" line.</para>  
</sect2>

</sect1>   
-->
<!--
<sect1 id='aims_training%aimsmasscenter' infoid=''>
<title>AimsMassCenter: </title>
  
<sect2><title>Options</title>  
<para>
<screen>

</screen>
</para>
</sect2>
  
<sect2><title>Example: </title>  
  <para> </para>
  <screen>
prompt%    
prompt%
prompt%
</screen>
<para></para> 
</sect2>

</sect1>   
-->

</chapter>  


<!--> <-->
<chapter>
<title>Conversion</title>

<sect1 id='aims_training%aimsdiffusionbundletoroi' infoid='usage of AimsDiffusionBundleToRoi'>
<title>AimsDiffusionBundleToRoi: conversion from bundles.bundles to ROI graph</title> 

<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsDiffusionBundleToRoi' target='blank'>command help for AimsDiffusionBundleToRoi</ulink></para>

<para><emphasis role='bold'>DATA: </emphasis>no data.</para>

<para><emphasis role='bold'>EXAMPLE: </emphasis></para> 
<screen>prompt% AimsDiffusionBundleAnalysis -i my_bundles.bundles -g my_bundles.arg</screen>

</sect1> 


<sect1 id='aims_training%aimsgraphconvert' infoid='usage of AimsGraphConvert'>
<title>AimsGraphConvert: conversion from label image to ROI graph</title> 

<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsGraphConvert' target='blank'>command help for AimsGraphConvert</ulink></para>

<para><emphasis role='bold'>DATA: </emphasis>no data.</para>

<para><emphasis role='bold'>EXAMPLE 1: </emphasis></para> 
<screen>prompt% AimsGraphConvert -i label_image.ima -o label_graphe.arg --bucket</screen>
<para><emphasis role='bold'>EXAMPLE 2: </emphasis>Mesh the graph.</para> 
<screen>prompt% AimsGraphMesh -i label_graphe.arg -o m_label_graphe.arg</screen>

<!-- <listitem>Optionally, you can use a nomenclature to link a region name with a specific color. Please see the <emphasis><ulink url="#ana_training%write_nomenclature">"Write a simple nomenclature (.hie)"</ulink></emphasis> section of <emphasis>The Anatomist getting started guide</emphasis>.</listitem>
</itemizedlist> 
-->
</sect1> 


<sect1 id='aims_training%aimsconversion' infoid='table of format conversions'>
<title>Table of format conversions</title> 

<para>Here are some very useful command lines to convert data. However, all command options are not explained in details. Please refer to the command help.</para>
<table>
<title>Table of format conversions</title>
<tgroup cols="4">
<thead>
<row>
<entry>Input (format/type)</entry>
<entry>Output (format/type)</entry>
<entry>commande line</entry>
<entry>Note</entry>
</row>
</thead>
<tbody>
<row>
<entry>GIS</entry><entry>MINC</entry>
<entry><screen>prompt% AimsFileConvert my_volume.ima my_volume.mnc</screen></entry><entry></entry>
</row>
<row>
<entry>.bundles</entry><entry>.arg</entry>
<entry><screen>prompt% AimsDiffusionBundleAnalysis -i my_bundles.bundles -g my_bundles.arg</screen></entry><entry></entry>
</row>
<row>
<entry>Label_image (volume)</entry><entry>.arg</entry>
<entry><screen>prompt% AimsGraphConvert -i label_image.ima -o label_graphe.arg --bucket</screen></entry><entry></entry>
</row>
<row> 
<entry>.arg</entry><entry>Label_image (volume)</entry>
<entry><screen>prompt% AimsGraphConvert -i roi.arg -o roi.arg --volume </screen></entry><entry>You will find roi_Volume.ima in roi.data directory</entry>
</row>
<row>
<entry>Volume</entry><entry>Cluster graph</entry>
<entry><screen>prompt% AimsClusterArg -i volume.ima -o cluster.arg</screen></entry><entry></entry>
</row>
<row>
<entry>Volume</entry><entry>Mesh</entry>
<entry><screen>prompt% AimsMesh -i label_image.ima -o label_image.mesh</screen></entry><entry></entry>
</row>
<row>
<entry>Mesh</entry><entry>Ascii</entry>
<entry><screen>prompt% AimsMesh2Ascii input.mesh mesh.txt</screen></entry><entry></entry>
</row>
<row>
<entry>Binary image</entry><entry>Mesh</entry>
<entry><screen>prompt% AimsMesh -i binary_mask.ima -o mask.mesh </screen></entry><entry>The output file will be mask_1_0.mesh</entry>
</row>
</tbody>
</tgroup>
</table>
</sect1>

</chapter> 






<!-->  <-->
<chapter>
<title>Calculation of images</title>

<sect1 id='aims_training%aimslinearcomb' infoid='using of AimsLinearComb'><title>AimsLinearComb: sum 2 activation maps</title>

<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsLinearComb' target='blank'>command help for AimsLinearComb</ulink></para>

<para><emphasis role='bold'>DATA: </emphasis>no data.</para>

<para><emphasis role='bold'>EXAMPLE: Sum of 2 activation maps.</emphasis> For instance, if you have 2 binary activation maps which have been obtained by functional analysis, and if you want to do a fusion of both, then you can create a new volume which will be the sum of map_I and map_II.</para>
<screen>
prompt% AimsLinearComb -i map_I.img -j map_II.img -o map_I+II.img
	options parsed
	i1      : map_I.img
	a       : 1
	b       : 1
	c       : 1
	d       : 1
	e       : 0
	i2      : map_II.img
	fileout : map_I+II.img
	type    :
	Reading image map_I.img...
	done
	reading image map_II.img...
	done
	processing...
	done
	writing result...
	done
</screen>

<figure><title>Sum of 2 activation maps</title><mediaobject>	
	<imageobject role="fop"><imagedata fileref="&DIR_IMG;aimslinearcomb.png" format="PNG"  width="150"/></imageobject>
	<imageobject role="html"><imagedata fileref="&DIR_IMG;aimslinearcomb.png" format="PNG"/></imageobject>
</mediaobject>
</figure>
<para>NOTE: image dimensions must be the same.</para>
<para>NOTE: you can use this command line to add several volumes; first add up map_I and map_II to create map_I+II and if you have a third volume, map_III to fusion with map_I and map_II, then you can use AimsLinearComb with map_I+II and map_III.</para>
<para>NOTE: advanced use, you can use multiplicative and divisor coefficients for each volume.</para>
</sect1>

<!-- 
<sect1 id='aims_training%cartoLinearComb' infoid='cartoLinearComb'>
<title>cartoLinearComb: Apply a formula to a set of homogeneous images (homogeneous means all of the same data type)</title> 
 <para>
Options:
  -h, - -help            show this help message and exit
  -o OUTPUT, - -output=OUTPUT
                        output volume
  -f FORMULA, - -formula=FORMULA
                        image formula, ex: ( I1 * 2 + I2 * I3 ) / 1.2
  -i FILENAME, - -input=FILENAME
                        input volume(s)
</para>


<para><emphasis role='bold'>EXAMPLE: </emphasis></para> 
<screen>prompt% cartoLinearComb -i image1.ima image2.ima -o image1+image2.ima -f I1 + I2</screen>
<para>NOTE: it is a beta version with some tricks, for example be aware that data don't have values to zero when
you want to do a division ....</para>
</sect1> 
-->


</chapter> 


<!--> <-->
<chapter>
<title>Handling meshes</title>

<sect1 id='aims_training%AimsConvexHull' infoid=''>
<title>Creation of a cube mesh from a point list</title> 

<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsConvexHull' target='blank'>command help for AimsConvexHull</ulink></para>

<para><emphasis role='bold'>DATA: </emphasis>no data.</para>

<para><emphasis role='bold'>EXAMPLE: </emphasis>
<itemizedlist>
<listitem><para>Write a the following text file and save under cube.txt:</para>
<literallayout>BEGIN------CUT HERE------BEGIN
8
0 0 0
10 0 0
0 10 0
10 10 0
0 0 10
10 0 10
0 10 10
10 10 10
END------CUT HERE------END
</literallayout></listitem>
<listitem><screen>prompt% AimsConvexHull -i cube.txt -o cube.mesh </screen></listitem>
</itemizedlist>
</para>
</sect1> 

<sect1 id='aims_training%aimszcat' infoid='using of AimsZCat'>
<title>AimsZCat: concatenates volumes (along Z axis), meshes or buckets</title>

<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsZCat' target='blank'>command help for AimsZCat</ulink></para>
	
<para><emphasis role='bold'>DATA: </emphasis><itemizedlist>
<listitem><filename>&DIR_BV;demo/subject01/tri/subject01_Lhemi.mesh</filename></listitem>
<listitem><filename>&DIR_BV;demo/subject01/tri/subject01_Rhemi.mesh</filename></listitem>				</itemizedlist></para>

<para><emphasis role='bold'>EXAMPLE: concatenation both right and left hemisphere meshes</emphasis></para> 
<screen>prompt% AimsZCat -i subject01_Lhemi.mesh subject01_Rhemi.mesh -o right_and_left_hemisphere.mesh</screen>
	
</sect1> 


</chapter> 



<!--> <-->
<chapter>
<title>Handling referentials and transformations</title>

<sect1 id="aims_training%referentials" infoid="referentials">
  <title>Coordinates systems in AIMS</title>

  <para>Here is a description of the coordinates sytems used in Aims and Anatomist, and what I have understood of how SPM handles its referentials.
  </para>

  <sect2>
    <title>AIMS and Anatomist</title>
    <sect3><title>Internally</title>
      <para>
        Anatomist uses AIMS to handle its referentials so behaves exactly the same way.
      </para>
      <para>Aims tries to work internally in an image-specific referential, but with always the same orientation. This orientation is axial with the following coordinates system:
        <itemizedlist>
          <listitem>X axis: right to left</listitem>
          <listitem>Y axis: front to back</listitem>
          <listitem>Z axis: top to bottom</listitem>
          <listitem>origin: the center of the <emphasis>first</emphasis> voxel: the voxel in the top, right, front corner
          </listitem>
        </itemizedlist>
        If you look at it you will realize that this referential is in <emphasis>radiological</emphasis> convention and is <emphasis>indirect</emphasis>. This is, in my opinion, a bad choice, but it's a bit too late to change.
      </para>
      <para>Once loaded in memory, all voxels should be organized in this order. As a consequence, images in Anatomist are always displayed in radiological mode, whatever the actual orientation of data on disk.
      </para>
    </sect3>

    <sect3><title>Externally</title>
      <para>
        Images on disk, depending on their format and acquisition modes, are not necessarily in this orientation. When a different orientation is detected, images are flipped in memory at load-time to fit the standard AIMS orientation. And when images are written back to disk, they may also be flipped back according to the specific format needs.
      </para>
    </sect3>

    <sect3><title>Transformations</title>
      <para>
        By default, AIMS doesn't apply any transformation other than flipping images at load time as described just before.
      </para>
      <para>
        But transformations can be provided in some Aims commands or loaded in Anatomist to apply coordinates changes. Then coords transformations are applied on the fly when processing or displaying data which are not in the same referential.
      </para>
      <para>There is no special referential (such as a common central working referential).
      </para>
      <para>
        Transformation files used by AIMS (<computeroutput>.trm</computeroutput> files) are ASCII files looking like this:
        <screen>
Tx Ty Tz
R11 R12 R13
R21 R22 R23
R31 R32 R33</screen>
        Tx, Ty, Tz are the translation components while the Rij coefficients are the linear matrix part. When used, these coefficients are applied as a "standard" 4x4 transformation matrix:
        <screen>
    [ R11  R12  R13  Tx ]
M = [ R21  R22  R23  Ty ]
    [ R31  R32  R33  Tz ]
    [   0    0    0   1 ]</screen>
      </para>
    </sect3>

    <sect3 id="aims_training%minf">
      <title><computeroutput>MINF</computeroutput> files</title>
      <para>
        AIMS (and Anatomist) writes an additional header file which can store any additional information: the <computeroutput>.minf</computeroutput> header (for Meta-INFormation) when saving its data (images, meshes, and any other data), and reads it if it is present when loading data files. This meta-header has the shape displayed by the <computeroutput>AimsFileInfo</computeroutput> command, and may be saved in "python dictionary" or XML formats. The MINF file has the same file name as the main data file, with the <computeroutput>.minf</computeroutput> extension added (<computeroutput>toto.img.minf</computeroutput> for instance).
      </para>
      <para>
        The MINF header may contain referentials and transformations information. When present, this information is stored in a few fields:
        <itemizedlist>
          <listitem>
            <emphasis role="bold"><computeroutput>referential</computeroutput></emphasis> may store an unique identifier (a cryptic characters string) to identify the AIMS referential for the current data file. If several data files refer to the same identifier, then they share the same referential and are considered to have coordinates in the same system.
          </listitem>
          <listitem>
            <emphasis role="bold"><computeroutput>referentials</computeroutput></emphasis> may store a list of target referentials for transformations specified in the <computeroutput>transformations</computeroutput> field. Both fields must have the same number of entries. Referentials are identified by character strings, either as unique identifiers or generic names (not necessarily unique). Some standard common referentials have specific names: "<computeroutput>Talairach-MNI template-SPM</computeroutput>" for the MNI normalization referential (used by SPM for instance), or "<computeroutput>Talairach-AC/PC-Anatomist</computeroutput>" for the referential based on anterior and posterior commissures used by the BrainVISA anatomical segmentation pipeline.
          </listitem>
          <listitem>
            <emphasis role="bold"><computeroutput>transformations</computeroutput></emphasis> may store a list of transformation matrices, each going from the AIMS data referential to the corresponding referential specified in the <computeroutput>referentials</computeroutput> field (same position in the list). Each transformation is a 4x4 matrix written as 16 numbers in rows, and assumes all coordinates are in millimeters.
          </listitem>
          <listitem>
            <emphasis role="bold"><computeroutput>storage_to_memory</computeroutput></emphasis> may store the disk orientation information, by providing the transformation between the disk storage voxels order and the memory orientation (the AIMS referential). This transformation is in the same shape as the <computeroutput>transformations</computeroutput> field, except that it is not a list, and the transformation is in voxels, not in mm.
          </listitem>
        </itemizedlist>
        For instance a MINF file may look like the following (in "python dictionary" format, here):
<screen>attributes = {
  'storage_to_memory' : [ 1, 0, 0, 0, 0, -1, 0, 62, 0, 0, -1, 45, 0, 0, 0, 1 ],
  'referentials' : [ 'Coordinates aligned to another file or to anatomical truth' ],
  'transformations' : [ [ -1, 0, 0, 78, 0, -1, 0, 75, 0, 0, -1, 84, 0, 0, 0, 1 ] ],
  'referential': 'be9724cc-eceb-d831-a83e-335e12b80f14',
}</screen>
        The referentials and transformations information in the MINF header may reflect information already stored in the specific format header (Analyze origin, or NIFTI-1 qform and sform, or MINC transformation).
      </para>
    </sect3>
  </sect2>

  <sect2>
    <title>SPM</title>

    <sect3><title>Internally</title>
      <para>
        Internally, SPM <emphasis>thinks</emphasis> things are always in the same orientation, which is also axial but with different axes:
        <itemizedlist>
          <listitem>X axis: left to right</listitem>
          <listitem>Y axis: back to front</listitem>
          <listitem>Z axis: bottom to top</listitem>
          <listitem>origin: the center of the voxel specified by the <emphasis>origin</emphasis> field of the SPM image header. This origin is specified in voxels and starts counting from 1 (not 0) like a matlab array index does.
          </listitem>
        </itemizedlist>
        This is a <emphasis>neurological</emphasis> convention orientation. The axes happen to be exactly the contrary of what is done in AIMS. Bad luck... But this referential is direct so cannot be considered worse than in AIMS...
      </para>
      <para>
        Working on the coordinate transformations for years and regularly getting headaches from it, I am still not 100% sure of what I say here, so if I'm wrong, please correct me by sending a message on BrainVisa forum (<ulink url="http://brainvisa.info/forum/">http://brainvisa.info/forum/</ulink>). Especially, I'm not sure that SPM99 and SPM2 really use the same referentials.
      </para>
    </sect3>

    <sect3><title>Externally</title>
      <para>
        SPM handles input Analyze images in two different orientations: axial radiological and axial neurological orientations. This orientation is <emphasis role="bold">not specified</emphasis> in SPM-Analyze format image files, so <emphasis role="bold">you</emphasis> have to tell how they are oriented. This is done in SPM by a flipping flag set somewhere in SPM defaults configuration (<computeroutput>default.analyze.flip</computeroutput> in SPM2).
      </para>
      <para>
        This is specific to SPM-Analyze format, and does not apply to NIFTI-1 or Minc formats. Hopefully the Analyze format is now obsolete and will disapear with time, but there are still existing files...
      </para>
      <para>This flipping flag has changed in form and meaning between SPM99 and SPM2.
      </para>
      <para>
        As I have understood:
        <itemizedlist>
          <listitem><emphasis role="bold">SPM99:</emphasis>
            <itemizedlist>
              <listitem>
                SPM99 uses the flipping flag only when normalizing images, indicating that the normalization process must perform or not a flip towards the normalization template. A clear indication of it is that the flag is part of the normalization parameters and is not present in other parts of SPM.
              </listitem>
              <listitem>
                Otherwise, SPM99 does not bother about the orientation of images. This is to say: even when displaying images, radiological images will be displayed with the left on the right of the display window, and neurological images with the left on the left, regardless of the flipping flag.
              </listitem>
              <listitem>
                Normalized images are <emphasis role="bold">always</emphasis> in neurological orientation whatever the orientation of input unnormalized images. Consequently, after normalizing a radiological image, loading both a normalized image and an unnormalized one in SPM will display them with different orientations.
              </listitem>
              <listitem>
                I am not sure if normalization templates have to be necessarily in neurological orientation or not but I guess yes because there is no way to indicate that the template is in radiological orientation.
              </listitem>
              <listitem>
                Normalization matrices for radiological data contain a X axis flip (negative 1st coefficient)
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem><emphasis role="bold">SPM2:</emphasis>
            <itemizedlist>
              <listitem>
                SPM2 uses the flipping flag at load time: radiological images are systematically flipped when loaded (and flipped back when rewritten so as to keep their radiological orientation on disk). This is true for <emphasis role="bold">all Analyze/SPM</emphasis> image files.
              </listitem>
              <listitem>
                This means all processings use it. As a consequence, all images are displayed in neurological orientation, left on the left, even for radiological images.
              </listitem>
              <listitem>
                But as this flag is global in SPM, <emphasis>all</emphasis> SPM images are considered to be in the same orientation: you cannot mix radio and neuro images. What I am pointing out here is only valid for SPM format images: SPM2 also handles MINC format, and Minc images contain orientation information.
              </listitem>
              <listitem>
                Normalized images are now in the same orientation as the input unnormalized image. Normalizing a radiological image will result in a normalized file in the radiological orientation (in SPM format). <emphasis role="bold">This is not what SPM99 used to do</emphasis>.
              </listitem>
              <listitem>
                SPM2 does not understand SPM99 and vice versa: no compatibility at all (neither forward nor backward): if you are using the radiological convention (like we are), loading in SPM2 an image normalized by SPM99 will result in a spurious flip and incorrect display and processing. This means you cannot use with SPM2 an image database built with SPM99.
              </listitem>
              <listitem>
                Normalization templates can be in either orientation. More precisely, I guess the template must be in the orientation specified by the flipping flag, or in Minc format in neurological orientation. I'm not completely sure of this. But this is perhaps an explanation of why the standard normalization template is now in Minc format and not in SPM format (otherwise its interpretation would depend on a user-defined flag).
              </listitem>
              <listitem>
                <para>
                  Last minute: I have just discovered that SPM now sometimes produces images with negative voxel sizes. I guess it is a kind of flipping indication, but I don't know from what to what else. And we know that all radiological images don't have this negative voxel size feature. So my opinion is that it's not reliable at all (at least unless you exactly know which version of SPM has written each image and this info is not available). This sign information is ignored in the current version of AIMS.
                </para>
                <para>The headache goes on...</para>
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem><emphasis role="bold">SPM5 ans SPM8:</emphasis>
            <itemizedlist>
              <listitem>
                SPM5 now uses the NIFTI-1 format for all output. NIFTI-1 specifies orientations and possibly transformations to standard referentials in its format, so this is a very good thing. Many problems are now solved.
              </listitem>
              <listitem>
                Otherwise I guess SPM5 behaves essentially like SPM2.
              </listitem>
              <listitem>
                The only little imperfection is that when SPM5 performs normalizations towards the MNI template, it does not indicate in output image that the target referential is the MNI template, but an unspecified other referential instead. So <emphasis role="bold">you</emphasis> have to know the target referential and specify it when needed (for instance in Anatomist).
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
      </para>
    </sect3>

    <sect3><title>Transformations</title>
      <para>
        SPM uses a common central referential to work in. Every image can provide a transformation matrix to this referential. Such a transformation may be specified in different ways:
        <itemizedlist>
          <listitem>an optional <computeroutput>.mat</computeroutput> file with the same name as the SPM format image. this was the way SPM99 and SPM2 behaved with Analyze format. But with SPM5 and SPM8, using NIFTI-1 formats avoids this need.
          </listitem>
          <listitem>If this <computeroutput>.mat</computeroutput> is not provided, then the file format header information is considered. NIFTI-1 provides full affine transformation matrices, but Analyze has only the origin translation, which is considered to be the only transformation needed to reach the central referential. If the .mat file is specified, information contained in it overrides some of the header information (including the origin).
          </listitem>
        </itemizedlist>
      </para>
      <para>
        Normalization files (<computeroutput>*_sn3d.mat</computeroutput> for SPM99, <computeroutput>*_sn.mat</computeroutput> for SPM2 and newer) contain transformations to the referential of a normalization template (either a standard one provided with the SPM software distribution, or a custom user-made one). This transformation contains an affine part (matrix), and optionally, depending on the normalization type, a non-linear part (coefficients on a functions base as far as I know but I don't know much about this part). Information about the input and template images are also included (dimensions, and origins or voxels-to-template transformation).
      </para>
      <para>
        Normalized images are in the referential of the normalization template used, but not necessarily with the same bounding box, resolution and field of view.
      </para>
      <para>
        SPM99 and SPM2 use normalization files with different names and different contents. They are not compatible, even if there is some common and similar information in them.
      </para>
    </sect3>
  </sect2>

  <sect2>
    <title>Changing between SPM and AIMS</title>

    <para>
      Due to the different internal orientations of the coordinate systems, going from SPM to AIMS and vice versa causes some serious problems.
    </para>

    <sect3><title>Normalization</title>
      <para>SPM normalization files are in matlab (<computeroutput>.mat</computeroutput>) format. AIMS cannot read the proprietary matlab format, so such files cannot be directly imported in AIMS.
      </para>
      <para>
        However, the scipy module for Python language can read them. So we have made Python scripts in PyAims and in BrainVisa to convert SPM matrices to AIMS <computeroutput>.trm</computeroutput> format. <emphasis role="bold">Only the affine part can be converted</emphasis>, because AIMS only use matrices for transformations, and non-linear information cannot fit into a matrix. Look at the <computeroutput>AimsSpmNormalizationConvert.py</computeroutput> program, and the <computeroutput>SPMsn3dToAims</computeroutput> process in BrainVISA.
      </para>
      <para>
        As the orientation is different in SPM and AIMS, a transformation to a template image is not the same as a transformation to a normalized image with a different field of view. So, when converting SPM normalization matrices, the normalized image must be also provided, otherwise BrainVisa can only give the transformation to the normalization template. Note the difference.
      </para>
    </sect3>
  </sect2>

  <sect2>
    <title>Issues</title>

    <sect3><title>Unnormalized SPM/Analyze images</title>
      <para>
        It is impossible to guess the orientation of such images if you don't know how they were acquired. This means you have to manually specify their orientation, either for all images in SPM, or in BrainVisa when importing them into a database. BrainVisa tags them so it knows everything afterwards and avoids mistakes. SPM does not.
      </para>
    </sect3>

    <sect3><title>Normalized SPM/Analyze images</title>
      <para>
        Normalizing the same image in radiological orientation with SPM99 and SPM2 results in normalized images in different orientations. When you import normalized images coming from another site, you have to know whether they have been normalized by SPM99 or by SPM2, and if the original image was in radiological or neurological orientation.
      </para>
      <para>
        I think the normalization file (<computeroutput>*_sn3d.mat</computeroutput> for SPM99, or <computeroutput>*_sn.mat</computeroutput> for SPM2) contains enough information to retreive the orientation of input and template images, so can disambiguate the situation.
      </para>
    </sect3>

    <sect3><title>Reading SPM/Analyze origin</title>
      <para>
        The origin field of SPM format is the position of the referential origin, in voxels and starting from 1 (not from 0). In fact it's a matlab array index. So it is given in the orientation of the image on disk. AIMS flips SPM images on several axes when loading them, so the origin information also has to be flipped. Flipping it needs to know the image dimensions.
      </para>
      <para>
        AIMS referentials have their origin in the first voxel, (almost) in the corner of the image, and normally don't use the SPM origin. But the origin information is read and maintained. Anatomist can, if asked for, make a transformation going from AIMS origin (corner) to the SPM origin. This allows to display several aligned SPM images in Anatomist with the correct correspondance. However after this translation, the coordinates are still in AIMS orientation (radiological and indirect), not in SPM, so the coordinates do not correspond to what they are in SPM.
      </para>
      <para>
        To compare coordinates of SPM images in Anatomist and SPM, another transformation has to be applied in Anatomist, with all the flips included. Anatomist can directly use the SPM/MNI normalization referential.
      </para>
    </sect3>

    <sect3><title>Other formats (GIS etc)</title>
      <para>
        Up to now, GIS images are considered being always in AIMS orientation unless specified in their AIMS meta-header (<computeroutput>.minf</computeroutput> file, see <link linkend="aims_training%minf">the corresponding paragraph</link>). No flips are applied.
      </para>
      <para>
        The Minc and NIFTI-1 IO plugins take orientation into account and flip data accordingly when reading / writing files.
      </para>
      <para>
        I am not sure if other formats (Dicom, Ecat...) can specify an image orientation or not. If they do, the current release of AIMS will probably not take it into account.
      </para>
    </sect3>
  </sect2>


  <sect2>
    <title>Technical details</title>

    <sect3><title>SPM normalization matrices conversion to AIMS world</title>
      <para>
        SPM99 and SPM2 don't use the same format of normalization files, but both provide more or less the following information:
        <itemizedlist>
          <listitem>
            An affine transformation matrix, called <computeroutput>Affine</computeroutput>, transforming coordinates from the template space to the input space, both sides in voxels arrays index, and indexed from 1 (not from 0)
          </listitem>
          <listitem>
            A voxels-to-mm transformation matrix for the input image, transforming voxels of the image into a mm position in the SPM internal orientation, taking the origin into account, and possibly rotations if the format supports it (NIFTI). This matrix is called <computeroutput>VF.mat</computeroutput> in SPM2 and also performs flipping, and called <computeroutput>MF</computeroutput> in SPM99 but doesn't seem to contain the flipping information. However for nomrmalization this millimetric referential is quite undefined and we will not really use it.
          </listitem>
          <listitem>
            Another voxel-to-mm matrix for the template image: <computeroutput>VG.mat</computeroutput> in SPM2, or <computeroutput>MG</computeroutput> in SPM99.
          </listitem>
          <listitem>
            Input and template image dimensions in voxels and a bit more: <computeroutput>VF.dim</computeroutput> and <computeroutput>VG.dim</computeroutput> in SPM2, or <computeroutput>Dims</computeroutput> in SPM99.
          </listitem>
        </itemizedlist>
      </para>
    </sect3>

    <sect3><title>Notations:</title>
      <para>
        <itemizedlist>
          <listitem>
            3 images: input (I call it Anatomy to be clearer), template, and normalized images. I use the suffixes A, T and N for coordinates on these 3 images.
          </listitem>
          <listitem>
            I use the same name for a given referential and coordinates in this referential: for instance <computeroutput>RAA</computeroutput> is both the AIMS referential of the anatomical image and a coordinates vector in it. I don't bother about standardized math notations: I don't remember them and haven't been using math anymore for many years. Don't ask me too much.
          </listitem>
          <listitem>
            AIMS referentials:
            <itemizedlist>
              <listitem>
                <computeroutput>RAA</computeroutput>: anatomy (in mm, radio convention, origin in 1st voxel)
              </listitem>
              <listitem>
                <computeroutput>RAAv</computeroutput>: anatomy (in voxels, radio convention, origin in 1st voxel)
              </listitem>
              <listitem>
                <computeroutput>RAAd</computeroutput>: anatomy (in voxels, disk storage ordering)
              </listitem>
              <listitem>
                <computeroutput>RAN</computeroutput>: normalized (in mm...)
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem>
            SPM referentials:
            <itemizedlist>
              <listitem>
                <computeroutput>RSA</computeroutput>: anatomy, in voxels
              </listitem>
              <listitem>
                <computeroutput>RST</computeroutput>: template, in voxels
              </listitem>
              <listitem>
                <computeroutput>RSCT</computeroutput>: template, "central" in mm
              </listitem>
              <listitem>
                <computeroutput>RSCN</computeroutput>: normalized, "central" in mm. Actually, <computeroutput>RSCT</computeroutput> and <computeroutput>RSCN</computeroutput> are the same.
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem>Transformation matrices:
            <itemizedlist>
              <listitem>
                <computeroutput>Affine</computeroutput>: the SPM affine matrix (voxels): <computeroutput>RST</computeroutput> to <computeroutput>RSA</computeroutput>
              </listitem>
              <listitem>
                <computeroutput>At</computeroutput>: SPM voxels to AIMS voxels transformation. This is only to take the array indexing starting at 1 in Matlab. So <computeroutput>At</computeroutput> is a <computeroutput>( -1, -1, -1 )</computeroutput> voxel translation. It can be used between <computeroutput>RSA</computeroutput> and <computeroutput>RAAd</computeroutput>, and either between <computeroutput>RSN</computeroutput> and <computeroutput>RANd</computeroutput>.
              </listitem>
              <listitem>
                <computeroutput>AIMS</computeroutput>: <computeroutput>RAA</computeroutput> to <computeroutput>RAN</computeroutput>, what we want to calculate. Here again, I'm maybe not using correctly math notations. I mean: <computeroutput>RAN = AIMS * RAA</computeroutput>.
              </listitem>
              <listitem>
                <computeroutput>VsA</computeroutput>: Aims voxels to mm anat
              </listitem>
              <listitem>
                <computeroutput>S2MA</computeroutput> Aims "<computeroutput>storage_to_memory</computeroutput>" anat matrix: disk voxels to Aims voxels.
              </listitem>
              <listitem>
                <computeroutput>A2T</computeroutput>: Aims anat-mm to template space-mm: <computeroutput>RAA</computeroutput> to <computeroutput>RSCT</computeroutput>, what we want to calculate if no normalized image is used.
              </listitem>
              <listitem>
                <computeroutput>TN</computeroutput>: normalized, Aims-mm to SPM-central-mm: <computeroutput>RAN</computeroutput> to <computeroutput>RSCN</computeroutput>
              </listitem>
              <listitem>
                <computeroutput>TCN</computeroutput>: template to normalized in SPM-mm: <computeroutput>RSCT</computeroutput> to <computeroutput>RSCN</computeroutput>. This transformation is identity in fact because the template and normalized images are in the same referential internally in SPM, but it's maybe clearer if I mention it.
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
        <figure><title>Referentials and normalization transformations</title>
        <mediaobject>
          <imageobject role="fop"><imagedata fileref="&DIR_IMG;normalization.png" format="PNG"  width="150"/>
          </imageobject>
          <imageobject role="html"><imagedata fileref="&DIR_IMG;normalization.png" format="PNG"/>
          </imageobject>
        </mediaobject>
        </figure>
      </para>
    </sect3>

    <sect3><title>Resolution:</title>
      <para>
        We want first <computeroutput>A2T</computeroutput>, then <computeroutput>AIMS</computeroutput>, provided <computeroutput>Affine</computeroutput>, <computeroutput>S2MA</computeroutput> and <computeroutput>MT</computeroutput>
      </para>
      <para>
<screen>  <emphasis role="bold">A2T = MT * ( VsA * S2MA * At * Affine )^-1</emphasis>
  <emphasis role="bold">AIMS = TN^-1 * A2T</emphasis>
</screen>
      </para>
    </sect3>
  </sect2>
</sect1>


<sect1 id='aims_training%aimsinverttransformation' infoid='compute the inverse transformation'>
<title>Compute the inverse transformation</title>

<para><emphasis role='bold'>HELP:  </emphasis><ulink url='&PATH_WEB;#aims_AimsInvertTransformation' target='blank'>command help for AimsInvertTransformation</ulink></para>

<para><emphasis role='bold'>DATA: </emphasis>no data.</para>

<screen>prompt% AimsInvertTransformation -i R1_TO_R2.trm -o R2_TO_R1.trm</screen>
</sect1> 

<sect1 id='aims_training%aimscomposetransformation' infoid='Compose a transformation'>
<title>Compose a transformation</title> 

<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsComposeTransformation' target='blank'>command help for AimsComposeTransformation</ulink></para>

<para><emphasis role='bold'>DATA: </emphasis>no data.</para>

<para>Let's imagine you have 3 referentials: R1, R2 and R3. You know R1-&gt;R2 (R1_TO_R2.trm) and R2-&gt;R3 (R2_TO_R3.trm). To compute R1-&gt;R3:</para>	
<screen>prompt% AimsComposeTransformation -i R2_TO_R3.trm R1_TO_R2.trm -o R1_TO_R3.trm</screen>
<para>NOTE_1: be aware, the order of transformation matrices is very important, this one is right <emphasis>-i R2_TO_R3.trm R1_TO_R2.trm</emphasis> but the following is completely wrong <emphasis>-i R1_TO_R2.trm R1_TO_R3.trm</emphasis>.</para>
<para>NOTE_2: if you have R3_TO_R2.trm and not R2_TO_R3.trm, you must first inverse this transformation matrix by using <link linkend='aims_training%aimsinverttransformation'>AimsInvertTransformation</link>	
	.</para>
</sect1> 

</chapter> 



<!--> <-->

<chapter>
<title>Handling graphs</title>
<sect1><title>Copy a set of graph attributes to another graph <!-- with the same structure--> </title>
	
<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsGraphConvert' target='blank'>command help for AimsGraphConvert</ulink></para>
		
<para><emphasis role='bold'>DATA: </emphasis>no data.</para>
	
<para>This case generally happens when working on automatically labelled sulci graphs. 
The nodes labels are given as the <emphasis>label</emphasis> attribute (automatic recognition labels), and you sometimes need to copy them to the <emphasis>name</emphasis> attribute (manual labelling). You have 2 possibilities to do it: manually or automatically.</para>
<para><emphasis role="bold">MANUALLY:</emphasis> you can verify each value of <emphasis>label</emphasis> attribute and correct it if necessary. To do so, change the value of the <emphasis>name</emphasis> attribute in a browser window (using a right-click on a graph node), and save the graph as a new graph (right-click on the graph in Anatomist control window and select <emphasis>File</emphasis> =&gt; <emphasis>Save</emphasis>).</para>

<para><emphasis role="bold">AUTOMATICALLY:</emphasis> you can use the <emphasis>AimsGraphConvert</emphasis> commandline. The following example shows how to use it:
							
<screen>prompt% AimsGraphConvert -i subjectAuto.arg -o subjectAutoName.arg -c label -d name </screen>
This command has many other options, but for the current application, the useful ones are:</para>

<itemizedlist>
<listitem><para><emphasis>-i option</emphasis>: input graph, for instance an autolabelled.</para></listitem>
<listitem><para><emphasis>-o option</emphasis>: output file name.<!-- For instance, you can name it by adding name of modified attribute. The associate .data directory is created by default with this name.--></para></listitem>
<listitem><para><emphasis>-c option</emphasis>: <!-- name of attribute uses like template (or for the copy)--> attribute to be copied.</para></listitem>
<listitem><para><emphasis>-d option</emphasis>: <!-- name of attribute for the destination--> destination attribute.</para></listitem>
<!-- use -b option to economize memory on computer -->
</itemizedlist>

</sect1>
</chapter>


<!-->  <-->

<chapter>
<title>Rigid registration</title>

<sect1 id='aims_training%aimsmanualregistration' infoid='using of AimsManualRegistration'>
<title>AimsManualRegistration: manual registration between 2 volumes from 3 specific landmarks.</title>

<para><emphasis role='bold'>KEYWORDS: </emphasis>.trm file.</para>	

<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsManualRegistration' target='blank'>command help for AimsManualRegistration</ulink></para>

<para><emphasis role='bold'>DATA: </emphasis>no data.</para>	

<para><emphasis role='bold'>EXAMPLE: MANUAL REGISTRATION BETWEEN 2 VOLUMES FROM 3 SPECIFIC LANDMARKS.</emphasis></para> 
<para>This example is based on 2 volumes (i.e. registration from image_1 to image2) using specific points (i.e. anatomical landmarks). By using the AimsManualRegistration command line, you will obtain a transformation matrix from image_1 to image_2 as a .trm file.</para>
<itemizedlist>
<listitem><para>For each volume, <ulink url='#ana_training%draw_roi'>draw a ROI</ulink> with exactly 3 regions (each region must contain only 1 voxel) with the same name per region (ie voxel_1, voxel_2, and voxel_3). So, you have the following ROIs: <filename>ROI_image_1.arg</filename> and <filename>ROI_image_2.arg</filename> with the structure of each ROI is composed by the regions: voxel_1, voxel_2 and voxel_3.</para></listitem>
<listitem><para>The command line is as follows: </para>
<screen>prompt% AimsManualRegistration -f ROI_image_1.arg -t ROI_image_2.arg -o ROI_image_1_TO_ROI_image_2.trm
</screen>
</listitem>
</itemizedlist>   
<para>NOTE: <ulink url='#ana_training%load_transformation'>to load a transformation, please refer to <emphasis>The Anatomist getting started guide</emphasis></ulink>.</para> 
	
</sect1> 

<sect1 id='aims_training%aimsmiregister' infoid='using of AimsMIRegister'>
<title>AimsMIRegister: registration based on mutual information.</title>

<para><emphasis role='bold'>KEYWORDS: </emphasis>.trm file.</para>	

<para><emphasis role='bold'>HELP: </emphasis><ulink url='&PATH_WEB;#aims_AimsMIRegister' target='blank'>command help for AimsMIRegister</ulink></para>

<para><emphasis role='bold'>DATA:</emphasis>
<itemizedlist>
<listitem><filename>&DIR_DEMO;Registration/anat.img</filename> </listitem>
<listitem><filename>&DIR_DEMO;Registration/fonc.ima</filename></listitem>
</itemizedlist></para>

<para>This command can appeare complex because a lot of options are available. In this section, we are going to try to define a reasonable use. The easier use is the following:</para>
<screen>prompt% AimsMIRegister -r anat.img -t fonc.ima --dir fonc_TO_anat.trm --inv anat_TO_fonc.trm
</screen>
<?lb?>

<para>Here are some options to optimize the registration. It is not advisable to use the other because the implementation is not totally finished.
<?lb?><?lb?><emphasis role='bold'>Initialization of registration: --gcinit, --seuilref and --seuiltest</emphasis>. There are 2 modes for initialization of registration. The <emphasis role='bold'> --gcinit 1</emphasis> mode (default mode) allows an initialization with the center of gravity. It works with <emphasis role='bold'> --seuilref</emphasis> (0.05 by default) and <emphasis role='bold'> --seuiltest</emphasis> (0.1 by default) options. These thresholds preserve a percentage of intensity according to the maximun intensity. Historically, this command was created to register PET and T1 RMI modalities, so to decrease the signal of PET data, a threshold was performed. And the <emphasis role='bold'> --gcinit 0</emphasis> mode allows an initialization with coordinates by using of <emphasis role='bold'> --Tx, --Ty, --Tz, --dTx, --dTy, --dTz, --Rx, --Ry, --Rz, --dRx, --dRy, --dRz</emphasis>. Parameters beginning with a <emphasis role='bold'>d</emphasis> corresponds to the exploration step, which is voxel=/2 by default.</para> 

<para><emphasis role='bold'>Speeding up the process</emphasis>, reference image can be damaged with a reduction factor according to the principle of a pyramid with <emphasis role='bold'> --refstartpyr</emphasis>:</para>	
<itemizedlist>
	<listitem><para><emphasis role='bold'> --refstartpyr 1</emphasis>:  1 voxel for 2 in the 3 directions = reduction of factor 8</para></listitem>
	<listitem><para><emphasis role='bold'> --refstartpyr 2</emphasis>:  1 voxel for 4 in the 3 directions = reduction of factor 64</para></listitem>
	<listitem><para><emphasis role='bold'> --refstartpyr 3</emphasis>:  1 voxel for 8 in the 3 directions = reduction of factor 562</para></listitem>
</itemizedlist>


</sect1>


</chapter>


<!--> <-->

<chapter>
<title>Advanced level</title>
<sect1 id='aims_training%symmetrical_roi' infoid='Get a symmetrical ROI'>
<title>Get a symmetrical ROI</title> 


<para><emphasis role='bold'>HELP: </emphasis><itemizedlist>
<listitem><ulink url='&PATH_WEB;#aims_AimsMidPlaneAlign' target='blank'>command help for AimsMidPlaneAlign</ulink></listitem>
<listitem><ulink url='&PATH_WEB;#aims_AimsLinearComb' target='blank'>command help for AimsLinearComb</ulink></listitem>
<listitem><ulink url='&PATH_WEB;#aims_AimsResample' target='blank'>command help for AimsResample</ulink></listitem>
<listitem><ulink url='&PATH_WEB;#aims_AimsThreshold' target='blank'>command help for AimsThreshold</ulink></listitem>
<listitem><ulink url='&PATH_WEB;#aims_AimsFlip' target='blank'>command help for AimsFlip</ulink></listitem>
</itemizedlist></para>

<!-- REF
     IEEE Trans Med Imaging. 2002 Feb;21(2):122-38.
     Computation of the mid-sagittal plane in 3-D brain images.
     
     * Prima S,
     * Ourselin S,
     * Ayache N.
     
     Epidaure Project, INRIA, Sophia Antipolis, France. prima@bic.mni.mcgill.ca
     
     We present a new method to automatically compute, reorient, and recenter the mid-sagittal plane in anatomical and functional three-dimensional (3-D) brain images. This iterative approach is composed of two steps. At first, given an initial guess of the mid-sagittal plane (generally, the central plane of the image grid), the computation of local similarity measures between the two sides of the head allows to identify homologous anatomical structures or functional areas, by way of a block matching procedure. The output is a set of point-to-point correspondences: the centers of homologous blocks. Subsequently, we define the mid-sagittal plane as the one best superposing the points on one side and their counterparts on the other side by reflective symmetry. Practically, the computation of the parameters characterizing the plane is performed by a least trimmed squares estimation. Then, the estimated plane is aligned with the center of the image grid, and the whole process is iterated until convergence. The robust estimation technique we use allows normal or abnormal asymmetrical structures or areas to be treated as outliers, and the plane to be mainly computed from the underlying gross symmetry of the brain. The algorithm is fast and accurate, even for strongly tilted heads, and even in presence of high acquisition noise and bias field, as shown on a large set of synthetic data. The algorithm has also been visually evaluated on a large set of real magnetic resonance (MR) images. We present a few results on isotropic as well as anisotropic anatomical (MR and computed tomography) and functional (single photon emission computed tomography and positron emission tomography) real images, for normal and pathological subjects.
     
     PMID: 11929100 [PubMed - indexed for MEDLINE]

     
     Utilisaiton du mode pyramide : il part d'une estimation grossiere depuis un niveau 3 puis reinitialise pour travailler en niveau 2 et ainsi de suite. Le niveau de pyramide correspond en fait au nombre de voxel agglomr.
     On pourrait faire : 
     start 3
     stop 2
    
     Note : il faut travailler sur des images en SHORT, sinon il faut faire une conversion.
     
     Note : Si on a R1, R2 et R3, ainsi que R1-&lt;R2, R2-&lt;R1 dduit de la precedente et R1-&lt;R3, 
     pour passer de R2  R3, attention  l'odre des transfo dans AimsComposeTransformation - i R1-&lt;R3 R2-&lt;R1 !

     Note : Le seuillage permet de recuperer une ROI +/- corrige (d'env 1/2 voxel) du reechantillonnage.
     -->
	
<para><emphasis role='bold'>DATA: </emphasis>no data.</para>	
	
<para>The purpose of this section is for instance to compare the ROI measurement for both hemispheres following the realignment of the brain by using a symmetric axe<!--. This section is difficult enough because there is a lot of command lines-->:
<itemizedlist>	
	
<listitem><para> <ulink url='#ana_training%draw_roi'>Draw a ROI</ulink> on the T1 MRI and export it as a mask to work with a .ima file (image) and not a .arg (graph): <filename>roi.ima</filename><!-- Note: convert from .arg to .ima --> </para></listitem>

<listitem><para>Use the AimsMidPlaneAlign command line to realign the image and compute the transformation (superposition of the interhemispheric plane with the plane x=dimX/2).</para>
<screen>prompt% AimsMidPlaneAlign -i rmiT1.ima -o align_rmiT1.ima</screen>
<para>NOTE: the transformation matrix is located in the input file directory with the following name <filename>rmiT1.ima_TO_align.ima.trm</filename>.<!-- Sorry, this name file is not really right because the file extension should be <emphasis>.trm</emphasis> to indicate the type of file. If necessary, you can change it to be recognized automatically by an application such as Anatomist.--></para></listitem>

<listitem><para>Do a linear combination if the ROI is a binary image :<!--, then you must do the following command to extend the grey levels:--></para>
<screen>prompt% AimsLinearComb -i roi.ima -o linearComb_roi.ima -a 16000</screen>
<para>NOTE: please refer to the table in NOTE_2 if the image is not binary.</para>
</listitem>

<listitem><para>Resample the ROI with the previously calculated transformation:</para>
<screen>prompt% AimsResample -i linearComb_roi.ima -o resample_roi.ima -m rmiT1.ima_TO_align.ima.trm</screen></listitem>

<listitem><para>Perform a threshold to 8000 to preserve a correct volume because the resampling widely extend the symmetric roi volume:</para>
<screen>prompt% AimsThreshold -i resample_roi.ima -o threshold_roi.ima -m ge -t 8000</screen></listitem>

<listitem><para>Get the symmetrical ROI by using AimsFlip as follows:</para>
<screen>prompt% AimsFlip -i threshold_roi.ima -o sym_roi.ima -m XX </screen></listitem>

<listitem><para>Each ROI can be in both referentials which are T1 and T1_align. In order to change the coordinate system, you apply a .trm. For instance, if you want the ROIs in T1 referential, you must resample the sym_roi.ima with the inverse of T1MRI.ima_TO_align.ima.</para>
<screen>prompt% AimsInvertTransformation -i rmiT1.ima_TO_align.ima.trm -o align.ima_TO_rmiT1.ima.trm</screen>
<para>Then, resample the sym_roi.ima: </para>
<screen>prompt% AimsResample -i sym_roi.ima -o sym_roi_RT1.ima -m align.ima_TO_rmiT1.ima.trm</screen>
</listitem>

<listitem><para>Analyze/compare the ROIs by using <link linkend='aims_training%aimsroifeatures'>AimsRoiFeatures</link>.</para></listitem>

</itemizedlist>	


</para> 

<para>NOTE_1: be aware that  the procedure presented below is not formal. In fact, many variations can be processed, the modality (PET, CT ...), how the ROI is obtained (draw on the original referential, or after the realignment) or where it comes from (i.e. created by an other process), what is the type of ROI value (binary, label image ...).<!-- In other words, each case can be different. Don't hesitate to test many ways.--></para>

<para>NOTE_2: here is a summary to help you compute and/or do a threshold of your ROI to preserve a correct volume (the resampling leads to volume changes):  
<table>
<title>Summary to preserve the ROI volume</title>
<tgroup cols="2">
<thead>
<row>
<entry>Max value</entry>
<entry>commande line</entry>
</row>
</thead>
<tbody>
<row>
<entry><para>Binary image (max=1)</para></entry>
<entry>
<para>
<screen>prompt% AimsLinearComb -i roi.ima -o roi.ima -a 16000
prompt% AimsResample -i roi.ima -o roi.ima -m motion.trm
prompt% AimsThreshold -i roi.ima -o roi.ima -m ge -t 8000
</screen>
</para>
</entry>
</row>
<row>
<entry><para>Max=max_value</para></entry>
<entry><para><screen>prompt% AimsLinearComb -i roi.ima -o roi.ima -a 16000 -b max_value
prompt% AimsResample -i roi.ima -o roi.ima -m motion.trm
prompt% AimsThreshold -i roi.ima -o roi.ima -m ge -t 8000
</screen></para></entry>
</row>
</tbody>
</tgroup>
</table>
</para>

<para>NOTE_3: for more information on the algorithm used by AimsMidPlaneAlign, please refer to <emphasis>Prima S, Ourselin S, and Ayache N. Computation of the mid-sagittal plane in 3-D brain images. IEEE Trans Med Imaging. 2002 Feb;21(2):122-38</emphasis>.</para>

</sect1>

</chapter> 






<!--

<chapter>
<title>Advanced level</title>

<para></para>
</chapter>


<chapter>
<title>Expert level</title>

<para></para>
</chapter>
 -->



<!--> <-->

<chapter id='aims_training%pyaims' infoid='Programming with AIMS in Python language'>
  <title>Programming with AIMS in Python language</title>

  <para>AIMS is a C++ library, but has python language bindings: <emphasis role="bold">PyAIMS</emphasis>. This means that the C++ classes and functions can be used from python. This has many advantages compared to pure C++:
    <itemizedlist>
      <listitem>Writing python scripts and programs is much easier and faster than C++: there is no fastidious and long compilation step.
      </listitem>
      <listitem>Scripts are more flexible, can be modified on-the-fly, etc
      </listitem>
      <listitem>It can be used interactively in a python interactive shell.
      </listitem>
      <listitem>As pyaims is actually C++ code called from python, it is still fast to execute complex algorithms. There is obviously an overhead to call C++ from python, but once in the C++ layer, it is C++ execution speed.
      </listitem>
    </itemizedlist>
    A few examples of how to use and manipulate the main data structures will be shown here.
  </para>

  <sect1>
    <title>Basics</title>

    <sect3>
      <title>Module importation</title>
      <para>In python, the aimsdata library is available as the <computeroutput>soma.aims</computeroutput> module.
        <screen>import soma.aims
# the module is actually soma.aims:
vol = soma.aims.Volume_S16( 100, 100, 100 )</screen>
        or:
        <screen>from soma import aims
# the module is available as aims (not soma.aims):
vol = aims.Volume_S16( 100, 100, 100 )
# in the following, we will be using this form because it is shorter.</screen>
      </para>
    </sect3>

    <sect3>
      <title>IO: reading and writing objects</title>

      <para>
        Reading operations are accessed via a single <computeroutput>read()</computeroutput> function, and writing through a single <computeroutput>write()</computeroutput> function. The <computeroutput>read()</computeroutput> function reads any object from a given file name, in any supported file format, and returns it:
        <screen>from soma import aims
obj = aims.read( 'data/volume_example.nii' )
print obj
obj2 = aims.read( 'data/volume_example2.ima' )
print obj2
obj3 = aims.read( 'data/mesh_example.mesh' )
print obj3
obj4 = aims.read( 'data/mesh_example2.gii' )
print obj4</screen>
        The returned object can have various types according to what is found in the disk file(s).
      </para>
      <para>
        Writing is just as easy. The file name extension generally determines the output format. An object read from a given format can be re-written in any other supported format, provided the format can actually store the object type.
        <screen>from soma import aims
obj2 = aims.read( 'data/volume_example2.ima' )
aims.write( obj2, '/tmp/vol_ex2.nii' )
obj3 = aims.read( 'data/mesh_example.mesh' )
aims.write( obj3, '/tmp/mesh_ex.gii' )
        </screen>
      </para>
      <highlights><emphasis role="bold">Exercise:</emphasis> write a little file format conversion tool
      </highlights>
    </sect3>

    <sect3>
      <title>Volumes</title>
    </sect3>

    <sect3>
      <title>Meshes</title>
    </sect3>

    <sect3>
      <title>Textures</title>
    </sect3>

    <sect3>
      <title>Buckets</title>
    </sect3>

    <sect3>
      <title>Graphs</title>
    </sect3>

  </sect1>


  <sect1>
    <title>Using algorithms</title>
  </sect1>

  <sect1>
  </sect1>

</chapter>


</book>
